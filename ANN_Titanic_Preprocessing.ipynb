{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff80137",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Preprocessing is a critical step in preparing data for neural networks. Raw data often contains inconsistencies, missing values, and varying scales that can significantly hinder the performance of a machine learning model. By preprocessing the data, we ensure that it is clean, well-structured, and ready for training. This process includes handling missing values, scaling numerical features, and encoding categorical variables. Proper preprocessing not only improves the model's accuracy but also speeds up the training process and helps avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34eeec",
   "metadata": {},
   "source": [
    "# Preprocessing the Titanic Dataset for ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3415f15",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates various preprocessing techniques on the Titanic dataset. \n",
    "We will go through the following steps to prepare the data for an artificial neural network (ANN):\n",
    "- Loading the dataset\n",
    "- Handling missing values\n",
    "- Scaling numerical features\n",
    "- Encoding categorical variables\n",
    "- Splitting the dataset into training and testing sets\n",
    "- Converting data into PyTorch tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58589c6a",
   "metadata": {},
   "source": [
    "## Loading the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7870fc",
   "metadata": {},
   "source": [
    "\n",
    "We will load the Titanic dataset using pandas. The dataset can be downloaded from Kaggle or other sources.                   \n",
    "**Explanation:** This code imports the pandas library, which is essential for data manipulation and analysis in Python. We load the Titanic dataset using the read_csv function, specifying the path to the dataset file. The head() function displays the first five rows of the dataset, allowing us to preview the data and understand its structure, including the columns and types of information present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89292040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "# Load the Titanic dataset\n",
    "data = pd.read_csv('titanic.csv')\n",
    "# Display the first few rows\n",
    "data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50beb2d",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94609b80",
   "metadata": {},
   "source": [
    "\n",
    "Handling missing values is crucial for machine learning models. In this step, we will fill missing numerical values with their mean.                                                                   \n",
    "**Explanation:** In this section, we first check for missing values in the dataset using the isnull() function, which returns a boolean DataFrame indicating missing entries. The sum() function counts the total number of missing values in each column. To address these missing values, we fill the Age column with its mean value and the Embarked column with its most frequent value (mode) using the fillna() method. This ensures that our dataset does not have any missing entries, which is crucial for training machine learning models.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb63ef63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "# Fill missing values in 'Age' and 'Fare' with mean values\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Check again for missing values\n",
    "data.isnull().sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0fb4a",
   "metadata": {},
   "source": [
    "## Scaling Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377e745",
   "metadata": {},
   "source": [
    "\n",
    "Neural networks perform better when input features are on a similar scale. We will use StandardScaler to scale numerical features such as `Age` and `Fare`.                                                                       \n",
    "**Explanation:** This section uses StandardScaler from the sklearn.preprocessing module to standardize the numerical features Age and Fare. Scaling is important for neural networks, as it helps to bring all features to a similar scale, improving convergence during training. The fit_transform() method calculates the mean and standard deviation of the specified features and transforms them into a standard normal distribution. The transformed values replace the original Age and Fare columns, and we display the first few rows of the scaled features to verify the changes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e593c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334993</td>\n",
       "      <td>-0.497811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.325530</td>\n",
       "      <td>-0.512660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.514175</td>\n",
       "      <td>-0.464532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.259330</td>\n",
       "      <td>-0.482888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.655545</td>\n",
       "      <td>-0.417971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare\n",
       "0  0.334993 -0.497811\n",
       "1  1.325530 -0.512660\n",
       "2  2.514175 -0.464532\n",
       "3 -0.259330 -0.482888\n",
       "4 -0.655545 -0.417971"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling 'Age' and 'Fare' features\n",
    "scaler = StandardScaler()\n",
    "data[['Age', 'Fare']] = scaler.fit_transform(data[['Age', 'Fare']])\n",
    "\n",
    "# Display scaled features\n",
    "data[['Age', 'Fare']].head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe925a3",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962e3fa",
   "metadata": {},
   "source": [
    "\n",
    "Categorical variables must be converted into numerical format for neural networks. We will use OneHotEncoder for this purpose.   \n",
    "**Explanation:** In this code block, we handle categorical variables by performing one-hot encoding on the Sex and Embarked columns. One-hot encoding converts categorical variables into a format that can be provided to machine learning algorithms, ensuring that they can interpret the data correctly. The get_dummies() function from pandas creates new binary columns for each category (e.g., 'male' and 'female' for Sex). The drop_first=True parameter helps to avoid multicollinearity by dropping the first category, resulting in cleaner datasets. We then display the first few rows of the encoded data to confirm the encoding process.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e9d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0.334993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>-0.497811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1.325530</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>-0.512660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>2.514175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>-0.464532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>-0.259330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>-0.482888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>-0.655545</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>-0.417971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name       Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James  0.334993      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  1.325530      1      0   \n",
       "2                     Myles, Mr. Thomas Francis  2.514175      0      0   \n",
       "3                              Wirz, Mr. Albert -0.259330      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist) -0.655545      1      1   \n",
       "\n",
       "    Ticket      Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
       "0   330911 -0.497811   NaN      True        True       False  \n",
       "1   363272 -0.512660   NaN     False       False        True  \n",
       "2   240276 -0.464532   NaN      True        True       False  \n",
       "3   315154 -0.482888   NaN      True       False        True  \n",
       "4  3101298 -0.417971   NaN     False       False        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# One-hot encoding 'Sex' and 'Embarked' columns\n",
    "encoded_data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "# Display encoded data\n",
    "encoded_data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edb998",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041dfa38",
   "metadata": {},
   "source": [
    "\n",
    "We will split the dataset into training and testing sets to train and evaluate our model.                     \n",
    "**Explanation:** This section splits the dataset into features (X) and the target variable (y). We drop the Survived column from the feature set and assign it to the target variable. The train_test_split() function from sklearn.model_selection is then used to randomly split the dataset into training and testing sets, with 80% of the data used for training and 20% for testing (as specified by test_size=0.2). The random_state=42 parameter ensures that the results are reproducible. We check the shapes of the training and testing sets to verify the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57424086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((334, 12), (84, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature set (X) and target (y)\n",
    "X = encoded_data.drop('Survived', axis=1)\n",
    "y = encoded_data['Survived']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of training and testing sets\n",
    "X_train.shape, X_test.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ca85d",
   "metadata": {},
   "source": [
    "## Converting Data to PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86377cb6",
   "metadata": {},
   "source": [
    "\n",
    "For training an ANN using PyTorch, we need to convert the dataset into tensors.                   \n",
    "**Explanation:** In this final section, we convert the training data into PyTorch tensors, which are necessary for training the artificial neural network. We use the torch.tensor() function to create tensors from the NumPy arrays of the training features (X) and labels (y). The dtype parameters ensure that the data types are correctly set for processing. A TensorDataset is then created, which pairs the features with the labels, and a DataLoader is instantiated to manage batches of data. By setting batch_size=32, we ensure that the model receives data in manageable chunks during training, and shuffle=True randomizes the data order for better training efficiency. The loop iterates through the data_loader, and we print the shapes of the batches to confirm that the batching is done correctly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e972e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: torch.Size([32, 5])\n",
      "Batch Y shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Select features and target variable, fill NaN values\n",
    "X = data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].fillna(0).values  # Fill NaNs with 0\n",
    "y = data['Survived'].values  # Target variable\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Continuous features\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)  # Categorical labels\n",
    "# Create TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "# Create DataLoader for batching\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "# Iterate through the DataLoader\n",
    "for batch_X, batch_y in data_loader:\n",
    "    print(\"Batch X shape:\", batch_X.shape)  # Check the shape of features\n",
    "    print(\"Batch Y shape:\", batch_y.shape)  # Check the shape of labels\n",
    "    break  # Break after the first batch for inspection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfab96",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we explored the essential preprocessing techniques necessary for preparing datasets for Artificial Neural Networks (ANNs). We highlighted the importance of handling missing values, scaling features, and encoding categorical variables. By following these steps, we can ensure that our data is clean, consistent, and ready for training. Proper preprocessing plays a vital role in enhancing model performance, enabling the ANN to learn effectively from the data and achieve better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4bf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
